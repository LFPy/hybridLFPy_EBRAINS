{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Potjans & Diesmann microcircuit  2014\n",
    "\n",
    "This example notebook submits a job to a chosen HPC backend of EBRAINS/HBP (**JUSUF**), loads a **Singularity** container with a complete **hybridLFPy** installation and executes the hybridLFPy example file ``example_microcircuit.py`` (https://github.com/INM-6/hybridLFPy/blob/master/examples/example_microcircuit.py) in parallel on the backend.\n",
    "\n",
    "For more in-depth info on using HPC backends via EBRAINS see https://wiki.ebrains.eu/bin/view/Collabs/using-supercomputers-from-the-collab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare connection to backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pyunicore==0.9.12 in /opt/app-root/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: PyJWT>=1.7 in /opt/app-root/lib/python3.6/site-packages (from pyunicore==0.9.12)\n",
      "Requirement already up-to-date: requests>=2.5 in /opt/app-root/lib/python3.6/site-packages (from pyunicore==0.9.12)\n",
      "Requirement already up-to-date: urllib3<1.27,>=1.21.1 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "Requirement already up-to-date: charset-normalizer~=2.0.0; python_version >= \"3\" in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "Requirement already up-to-date: idna<4,>=2.5; python_version >= \"3\" in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# use the pyunicore library\n",
    "!pip install pyunicore==0.9.12 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pyunicore.client as unicore_client\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "from pprint import pprint\n",
    "from IPython.display import IFrame, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection to supercomputer (i.e., JUSUF)\n",
    "tr = unicore_client.Transport(clb_oauth.get_token())\n",
    "r = unicore_client.Registry(tr, unicore_client._HBP_REGISTRY_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JUWELS': 'https://zam2125.zam.kfa-juelich.de:9112/JUWELS/rest/core',\n",
       " 'JUSUF': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core',\n",
       " 'UNICORE-TEST': 'https://catto.cscs.ch:8080/UNICORE-TEST/rest/core',\n",
       " 'BSC-MareNostrum': 'https://unicore-hbp.bsc.es:8080/BSC-MareNostrum/rest/core',\n",
       " 'JURECA': 'https://zam2125.zam.kfa-juelich.de:9112/JURECA/rest/core',\n",
       " 'DAINT-CSCS': 'https://brissago.cscs.ch:8080/DAINT-CSCS/rest/core',\n",
       " 'CINECA-MARCONI': 'https://grid.hpc.cineca.it:9111/CINECA-MARCONI/rest/core',\n",
       " 'CINECA-G100': 'https://grid.hpc.cineca.it:9111/CINECA-G100/rest/core',\n",
       " 'CINECA-M100': 'https://grid.hpc.cineca.it:9111/CINECA-M100/rest/core',\n",
       " 'JUDAC': 'https://zam2125.zam.kfa-juelich.de:9112/JUDAC/rest/core'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valid choices for supercomputers are one of the keys in:\n",
    "r.site_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one HPC resource\n",
    "supercomputer = 'JUSUF'\n",
    "try:\n",
    "    site_client = r.site(supercomputer)\n",
    "except KeyError:\n",
    "    # cluster may be dropped from Registry.site_urls for whatever reason\n",
    "    site_client = unicore_client.Client(r.transport, \n",
    "                                        'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': {'selected': 'user', 'availableRoles': ['user']},\n",
       " 'queues': {'availableQueues': ['batch', 'develgpus'], 'selected': 'batch'},\n",
       " 'dn': 'UID=espen.hagen@nmbu.no',\n",
       " 'xlogin': {'UID': 'hagen2',\n",
       "  'availableGroups': ['icei-hbp-2020-0004'],\n",
       "  'availableUIDs': ['hagen2'],\n",
       "  'group': 'icei-hbp-2020-0004'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_client.access_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override group entry in case of multiple allocations\n",
    "# site_client.transport.preferences = \"group:icei-hbp-2020-0004\"\n",
    "# site_client.access_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code 200 \n",
      "Content-type application/json \n"
     ]
    }
   ],
   "source": [
    "# check connection to supercomputer\n",
    "headers = {}\n",
    "headers[\"Authorization\"] = \"Bearer \" + clb_oauth.get_token()\n",
    "headers['Accept'] = \"application/json\"\n",
    "rs = requests.get(url=site_client.site_url, headers = headers, verify = False)\n",
    "print(\"Status code %s \" % rs.status_code)\n",
    "print(\"Content-type %s \" % rs.headers['Content-Type'])\n",
    "reply = rs.json()\n",
    "# print(json.dumps(reply, indent = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare singularity container\n",
    "See https://apps.fz-juelich.de/jsc/hps/jusuf/cluster/container-runtime.html#container-runtime-on-system-name for details. \n",
    "\n",
    "This step builds the singularity container. It is optional if the recipe has already been uploaded and built on the system. \n",
    "\n",
    "The procedure may be different on different HPC backends. \n",
    "The container can either way be built from the same recipe: https://raw.githubusercontent.com/INM-6/hybridLFPy/master/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the below Raw block into Code in order to run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# build singularity container with LFPy etc. using a Dockerfile. \n",
    "# This step only needs to be done once per user/project (possibly). \n",
    "build_job = {\n",
    "  \"Executable\" : \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "\n",
    "## create sib config file; uncomment below files to create them\n",
    "#mkdir -p ~/.config/sib\n",
    "#cat > ~/.config/sib/settings.ini <<'EOF'\n",
    "#[config]\n",
    "#url_prefix=https://sbuild-hps.fz-juelich.de/\n",
    "#EOF\n",
    "\n",
    "sib upload ./Dockerfile hybridlfpy\n",
    "sib build  # −−recipe−name hybridlfpy −−blocking\n",
    "sib wait-for-completion\n",
    "\"\"\",\n",
    "    \n",
    "  \"Job type\": \"interactive\",\n",
    "}\n",
    "build_job = site_client.new_job(job_description=build_job, inputs=[])\n",
    "while build_job.is_running():\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare main simulation job\n",
    "This step combines in a single session the following:\n",
    "\n",
    "- download hybridLFPy container\n",
    "- download simulation files from GitHub (https://github.com/INM-6/hybridLFPy)\n",
    "- ask for resources (# nodes, # MPI processes, # seconds runtime)\n",
    "- execute simulation via the batch job queue\n",
    "- download tar file with simulation output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Singularity exposes the host environment to the running container (i.e., ``$PATH``, ``$PYTHONPATH``, ``$HOME`` etc.). \n",
    "The container includes Python 3.8.5, and may find pip-installed software in your host's ``$HOME/.local/lib/python3.8/site-packages`` directory and similar if it exist. \n",
    "\n",
    "If you encounter problems, try including ``unset PYTHONPATH`` in your ``simulation_job[\"Executable\"]`` part below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with job specification and define list of input files from this Collab\n",
    "# simulation_job = {\"Job type\": \"interactive\"}\n",
    "simulation_job = {}\n",
    "simulation_inputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "simulation_job['Resources'] = {\n",
    "    \"Queue\": \"batch\",\n",
    "    \"Nodes\": \"4\",\n",
    "    \"CPUsPerNode\": \"128\",\n",
    "    #\"CPUs\": \"512\",\n",
    "    \"Runtime\": \"3600\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands run on login node before job execution\n",
    "simulation_job[\"User precommand\"] = \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools git\n",
    "\n",
    "git clone --branch master --depth 1 https://github.com/INM-6/hybridLFPy.git\n",
    "cd hybridLFPy/examples\n",
    "sib download --recipe-name hybridlfpy\n",
    "\"\"\"\n",
    "simulation_job[\"RunUserPrecommandOnLoginNode\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set some environment variables\n",
    "# - run the python code using interpreter embedded in container\n",
    "simulation_job[\"Executable\"] = \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "unset DISPLAY  # matplotlib may look for a nonexistant display on compute node(s)\n",
    "export SINGULARITYENV_SCRATCH=  # make container unaware of $SCRATCH area as we are already there - write sim output to simulation script folder\n",
    "export SINGULARITYENV_PYTHONPATH=/opt/nest/lib/python3.9/site-packages\n",
    "cd hybridLFPy/examples  # go to examples\n",
    "srun --mpi=pmi2 singularity exec hybridlfpy.sif python3 -u example_microcircuit.py  # execute simulation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands run after job is done\n",
    "simulation_job[\"User postcommand\"] = \"\" \n",
    "simulation_job[\"RunUserPostcommandOnLoginNode\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Resources': {'Queue': 'batch',\n",
       "  'Nodes': '4',\n",
       "  'CPUsPerNode': '128',\n",
       "  'Runtime': '3600'},\n",
       " 'User precommand': 'module use $OTHERSTAGES\\nmodule --force purge\\nmodule load Stages/2020\\nmodule load GCC Singularity-Tools git\\n\\ngit clone --branch master --depth 1 https://github.com/INM-6/hybridLFPy.git\\ncd hybridLFPy/examples\\nsib download --recipe-name hybridlfpy\\n',\n",
       " 'RunUserPrecommandOnLoginNode': 'true',\n",
       " 'Executable': 'module use $OTHERSTAGES\\nmodule --force purge\\nmodule load Stages/2020\\nmodule load GCC Singularity-Tools\\nunset DISPLAY  # matplotlib may look for a nonexistant display on compute node(s)\\nexport SINGULARITYENV_SCRATCH=  # make container unaware of $SCRATCH area as we are already there - write sim output to simulation script folder\\nexport SINGULARITYENV_PYTHONPATH=/opt/nest/lib/python3.9/site-packages\\ncd hybridLFPy/examples  # go to examples\\nsrun --mpi=pmi2 singularity exec hybridlfpy.sif python3 -u example_microcircuit.py  # execute simulation\\n',\n",
       " 'User postcommand': '',\n",
       " 'RunUserPostcommandOnLoginNode': 'true'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create job\n",
    "job = site_client.new_job(job_description=simulation_job, inputs=simulation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Storage: https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/storages/da6e75a2-fca4-4a94-9869-48fee1466639-uspace"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " \"Mon Nov 22 08:58:35 CET 2021: Created with ID da6e75a2-fca4-4a94-9869-48fee1466639\",\n",
      " \"Mon Nov 22 08:58:35 CET 2021: Created with type 'JSON'\",\n",
      " \"Mon Nov 22 08:58:35 CET 2021: Client: Name: UID=espen.hagen@nmbu.no\\nXlogin: uid: [hagen2], gids: [icei-hbp-2020-0004, addingOSgroups: true]\\nRole: user: role from attribute source\\nQueues: [batch:develgpus, selected=batch]\\nSecurity tokens: User: UID=espen.hagen@nmbu.no\\nClient's original IP: 134.94.88.93\",\n",
      " \"Mon Nov 22 08:58:37 CET 2021: No staging in needed.\",\n",
      " \"Mon Nov 22 08:58:37 CET 2021: Status set to READY.\",\n",
      " \"Mon Nov 22 08:58:37 CET 2021: Status set to PENDING.\",\n",
      " \"Mon Nov 22 08:58:37 CET 2021: Launched pre command <module use $OTHERSTAGES\\nmodule --force purge\\nmodule load Stages/2020\\nmodule load GCC Singularity-Tools git\\n\\ngit clone --branch master --depth 1 https://github.com/INM-6/hybridLFPy.git\\ncd hybridLFPy/examples\\nsib download --recipe-name hybridlfpy\\n>\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(job.properties['log'], indent = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'--No graphics will be displayed.\\n',\n",
      " b'Translating alphaisyn.mod into /p/scratch/icei-hbp-2020-0004/unicore-jobs/da'\n",
      " b'6e75a2-fca4-4a94-9869-48fee1466639/hybridLFPy/examples/x86_64/alphaisyn.c\\n',\n",
      " b'Translating expsyni.mod into /p/scratch/icei-hbp-2020-0004/unicore-jobs/da6e'\n",
      " b'75a2-fca4-4a94-9869-48fee1466639/hybridLFPy/examples/x86_64/expsyni.c\\n',\n",
      " b'Thread Safe\\n',\n",
      " b'Thread Safe\\n']\n",
      "[b'Execution time: 721.552 seconds\\n',\n",
      " b'Execution time: 720.841 seconds\\n',\n",
      " b'Execution time: 720.590 seconds\\n',\n",
      " b'Execution time: 720.536 seconds\\n',\n",
      " b'Execution time: 721.579 seconds\\n',\n",
      " b'Execution time: 720.964 seconds\\n',\n",
      " b'Execution time: 720.819 seconds\\n',\n",
      " b'Execution time: 720.546 seconds\\n',\n",
      " b'Execution time: 720.542 seconds\\n',\n",
      " b'Execution time: 720.586 seconds\\n']\n"
     ]
    }
   ],
   "source": [
    "# wait while job is running and track progress\n",
    "while job.is_running():\n",
    "    clear_output()\n",
    "    # STDERR output (if any)\n",
    "    try:\n",
    "        stderr = job.working_dir.stat('stderr')\n",
    "        #pprint(stderr.raw().readlines()[:5])\n",
    "        pprint(stderr.raw().readlines()[-5:])\n",
    "    except:\n",
    "        print('no stderr file to read yet')\n",
    "    # STDOUT output\n",
    "    try:\n",
    "        stdout = job.working_dir.stat('stdout')\n",
    "        #pprint(stdout.raw().readlines()[:10])\n",
    "        pprint(stdout.raw().readlines()[-10:])\n",
    "    except:\n",
    "        print('no stdout file to read yet')\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['UNICORE_SCRIPT_EXIT_CODE', 'stderr', 'hybridLFPy/', 'bss_submit_1637567975267', 'stdout', '.UNICORE_POST_0/', '.UNICORE_PRE_0/', 'UNICORE_Job_1637567975267'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.working_dir.listdir().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download simulation output\n",
    "job.working_dir.stat('hybridLFPy/examples/simulation_output_example_microcircuit.tar'\n",
    "                     ).download('simulation_output_example_microcircuit.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill job, clean up files on the remote\n",
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate simulation output\n",
    "Here we choose to print some pdf file output from the simulation, however all simulation output are available within the same simulation output file hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove old simulation output (if present) and untar output to folder example_network_output\n",
    "!rm -r simulation_output_example_microcircuit\n",
    "!tar -xf simulation_output_example_microcircuit.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./simulation_output_example_microcircuit/figures/layers.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f759e0873c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./simulation_output_example_microcircuit/figures/layers.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./simulation_output_example_microcircuit/figures/cell_models.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f759e087400>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at e.g., the extracellular potential and spike raster plot\n",
    "IFrame(\"./simulation_output_example_microcircuit/figures/cell_models.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./simulation_output_example_microcircuit/figures/soma_locations.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f759e087160>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./simulation_output_example_microcircuit/figures/soma_locations.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./simulation_output_example_microcircuit/figures/network_raster.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f759e087ac8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./simulation_output_example_microcircuit/figures/network_raster.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./simulation_output_example_microcircuit/figures/compound_signals.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f759e087080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./simulation_output_example_microcircuit/figures/compound_signals.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./simulation_output_example_microcircuit/figures/current_dipole_moments.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f759e087b38>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./simulation_output_example_microcircuit/figures/current_dipole_moments.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
